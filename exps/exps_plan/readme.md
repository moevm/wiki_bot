# Мотивация

Мы собрали данные, попробовали первый подход, самое время понять, что делать дальше. Хочется собрать список подходов, распределить их между участниками и распараллелить работу.

# Описание

## Идея 

### Постановка и описание общих подходов
Мне кажется, настало время расписать планируемые подходы/эксперименты. Сначала определим задачу:
У нас есть вопрос пользователя, информация о предмете и курсе. В ответ на это мы должны выдать ссылку на документ, а лучше конкретный текст с ответом на вопрос.


Есть два типичных подхода к решению задачи:
1) Retrieval Based

Есть база ответов - выбери из них. Такие штуки обычно хорошо работают, если ответы написаны людьми и у нас очень большая база пар вопрос-ответ. 
Там ищется самый похожий вопрос и выдаётся ответ на него. Но у нас нет таких данных...
Поэтому мы можем попробовать искать сразу ответ, похожий на вопрос. Конечно, это хуже потому что находить похожие вопросы легче, чем сразу ответы.
Базовые проблемы алгоритма:
- Мы заранее ограничены множеством ответом
- Задача мапить вопрос на ответ в общем случае совсем не тривиальна

2) Generative based

Есть вопрос от юзера - сгенерируй ответ произвольным способ. Хочешь - возьми марковскую цепь, хочешь - возьми хайповый Трансформер. 

Базовые проблемы
1) А откуда модель узнает специфику твоего домена? Откуда в ней знания об этом?
2) Рискуем нагенерить бред, не имеющий отношения к вопросу
3) А как качество то считать? Если в retrieval заранее знаем нужный id-шник, то тут нам произвольный текст выдают

### Конкретные подходы

1) BM25
Поисковый индекс поверх частотности слов
2) Предобученный берт + KNN
Вектора из берта + поиск ближайшего(текущая реализация)
3) По ссылке есть куча моделей, мы попробовали LaBSE, но это так, стандарт в плане получения векторов. Там есть штуки, которые учились специально под семантичкий поиск(как симметричный, так и ассиметричный)
https://www.sbert.net/examples/applications/semantic-search/README.html
4) Есть подходы поверх графов(про это я мало знаю)
https://github.com/heathersherry/Knowledge-Graph-Tutorials-and-Papers
5) Реализуем пейпер(вроде реализация есть итак + есть интеграция с sentence transformers)
https://arxiv.org/pdf/2202.08904.pdf
6) Различные подходы к генеративным моделям
Тут можно пробовать кучу моделек. Выбор есть и среди архитектур(T5/GPT), так и среди подходов(обучалась с инструкциями или нет). Ну и чекпоинтов вон куча. Миллион тюнов ламы, есть её тюны под русский, буквально в момент написания сего текста вышла первая итерация OpenAssistant с русским в датасете. xglm тоже можно попробовать/затюнить с инструкциями(такое и опубликовать для людей не стыдно, прямо скажем)
  - Берём текст страницы + вопрос, закидываем в модель и спрашиваем есть ли в странице ответ на наш вопрос.

  - Берём модель и файнтюним на наших данных, потом делаем описанное в прошлом пункте 

  - Вообще любая шиза, что пришла вам в голову, это же генеративная модель, хоть декодер отпилите и что-то с ним делайте, вроде были такие пейперы

7) Берём и чекаем умеет ли что-нибудь из коробки ElasticSearch/OpenSearch - если да, поднимаем свой инстанс и тестим
8) BertTopic
9) Есть огромный фреймворк, там много крутых слов написано, но я с ним не работал. Однако задача наша, можно ворваться и потестить, даже не разбираясь чё там под капотом(качество выстрелит - разберёмся)

https://github.com/deepset-ai/haystack

10) Крутить ансамбли поверх лучшего предложенного. Это уже страшные(вычислительно) вещи, конечно, но докинуть может. Можно обычные блендинги взять, можно хоть многоруких бандитов навернуть

## Реализация 

Предполагается, что у нас есть один согласованный валидационный сет. Исполнитель задачи пробует свой подход, измеряет качество на предложенном валсете, потом мы выбираем лучший подход.

На данный момент у нас есть [собранные данные в виде html](https://drive.google.com/file/d/1Ux-pxb60t14RPjeZJ_lyuWzHW4J9JAq5/view?usp=share_link) и [валсет](https://drive.google.com/file/d/1-e9oVyTMLMIyYnhUT-yWO38mA4ZzTuov/view?usp=share_link). **Настоятельно рекомендуется в коде скачивать эти файлы или хотя бы задавать путь до них, чтобы другим легко было запустить Ваш код у себя**


# Результаты

У нас есть список предлагаемых экспов.
